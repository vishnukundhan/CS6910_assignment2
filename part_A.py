# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N6R5xhSoj5COUdlfBaziPtzzWqR0a4qs
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, SubsetRandomSampler
class CNN(nn.Module):
    def __init__(self, filters, denseLayer, activation, inputShape, outputShape, dropout, learningRate, batchNorm, weightDecay):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(inputShape[0], filters[0], kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(4*4*filters[4], denseLayer)
        self.fc2 = nn.Linear(denseLayer, outputShape)
        self.activation = getattr(nn, activation)()
        self.dropout = nn.Dropout(dropout)
        self.batch_norm = nn.BatchNorm2d(filters[0]) if batchNorm else None
        self.weight_decay = weightDecay
        self.learning_rate = learningRate
        self.y = filters[4]

    def forward(self, x):
        x = self.pool(self.activation(self.conv1(x)))
        x = self.pool(self.activation(self.conv2(x)))
        x = self.pool(self.activation(self.conv3(x)))
        x = self.pool(self.activation(self.conv4(x)))
        x = self.pool(self.activation(self.conv5(x)))
        x = x.view(-1, self.y*4*4)
        x = self.dropout(self.activation(self.fc1(x)))
        x = self.fc2(x)
        return x

transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

trainDataset = datasets.ImageFolder("/kaggle/input/inaturalist12k/Data/inaturalist_12K/train/", transform=transform)
trainIndices, valIndices = train_test_split(list(range(len(trainDataset))), test_size=0.2, random_state=42)
trainSampler, valSampler = SubsetRandomSampler(trainIndices), SubsetRandomSampler(valIndices)

def trainNetwork():
    with wandb.init() as run:
        config = wandb.config
        trainLoader = DataLoader(trainDataset, batch_size=config.batchSize, sampler=trainSampler)
        valLoader = DataLoader(trainDataset, batch_size=config.batchSize, sampler=valSampler)
        model = CNN(
            config.filters,
            config.denseLayer,
            config.activation,
            (3, 128, 128),
            10,
            config.dropout,
            config.learningRate,
            config.batchNorm,
            config.weightDecay
        )
        lossCriteria = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=config.learningRate, weight_decay=config.weightDecay)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        for i in range(config.epochs):
            model.train()
            tempLoss = 0.0
            true = 0
            total = 0
            for inputs, labels in trainLoader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = lossCriteria(outputs, labels)
                loss.backward()
                optimizer.step()
                tempLoss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                true += predicted.eq(labels).sum().item()

            trainLoss = tempLoss/len(trainLoader)
            trainAccuracy = 100*(true/total)
            valLoss, valAccuracy = validateNetwork(valLoader, model)

            print(f"epoch {i+1}/{config.epochs}: train loss: {trainLoss}, train accuracy: {trainAccuracy}, val loss: {valLoss}, val accuracy: {valAccuracy}")


def validateNetwork(valLoader,model):
    model.eval()
    valLoss = 0.0
    true = 0
    total = 0
    lossCriteria = nn.CrossEntropyLoss()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    with torch.no_grad():
        for inputs, labels in valLoader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            loss = lossCriteria(outputs, labels)
            valLoss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            true += predicted.eq(labels).sum().item()

    valLoss /= len(valLoader)
    valAccuracy = 100*(true/total)
    return valLoss, valAccuracy

# Sweep configuration
# Parse arguments
parser = argparse.ArgumentParser(description='CNN Training Configuration')
parser.add_argument('--weightDecay', type=float, default=0.0001)
parser.add_argument('--dropout', type=float, default=0.1)
parser.add_argument('--learningRate', type=float, default=0.0001)
parser.add_argument('--activation', type=str, default='ReLU')
parser.add_argument('--batchNorm', type=bool, default=True)
parser.add_argument('--filters', type=list, default=[32, 32, 32, 32, 32])
parser.add_argument('--dataAug', type=bool, default=True)
parser.add_argument('--batchSize', type=int, default=32)
parser.add_argument('--denseLayer', type=int, default=64)
parser.add_argument('--epochs', type=int, default=5)

args = parser.parse_args()

# Train the network with the parsed arguments
trainNetwork(args)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, SubsetRandomSampler
!pip install wandb
import wandb
wandb.init(entity="vishnukundhan333", project="DL Assignment-2")
#QUESTION 1
#Creating a CNN layer with 5 layers with activation and maxpolling function between layers
# Define a CNN model
class CNN(nn.Module):
    def __init__(self, filters, denseLayer, activation, inputShape, outputShape, dropout, learningRate, batchNorm, weightDecay):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(inputShape[0], filters[0], kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(4*4*filters[4], denseLayer)
        self.fc2 = nn.Linear(denseLayer, outputShape)
        self.activation = getattr(nn, activation)()
        self.dropout = nn.Dropout(dropout)
        self.batch_norm = nn.BatchNorm2d(filters[0]) if batchNorm else None
        self.weight_decay = weightDecay
        self.learning_rate = learningRate
        self.y = filters[4]
# forward function is used to train the model across the layers until the last final classification layer for the input data
    def forward(self, x):
        x = self.pool(self.activation(self.conv1(x)))
        x = self.pool(self.activation(self.conv2(x)))
        x = self.pool(self.activation(self.conv3(x)))
        x = self.pool(self.activation(self.conv4(x)))
        x = self.pool(self.activation(self.conv5(x)))
        x = x.view(-1, self.y*4*4)
        x = self.dropout(self.activation(self.fc1(x)))
        x = self.fc2(x)
        return x

# Resizing the data as there are different image resolutions so a simple and suitable resolution is used .
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

#Splitting the data into two parts of validation and train ,20% is done for validation
testDataset = datasets.ImageFolder("/kaggle/input/inaturalist12k/Data/inaturalist_12K/val/", transform=transform)
testLoader = DataLoader(testDataset, batch_size=32)

#Train function to train the model of 5 layers CNN
def trainNetwork():
    with wandb.init() as run:
        config = wandb.config
        model = CNN(
            config.filters,
            config.denseLayer,
            config.activation,
            (3, 128, 128),
            10,
            config.dropout,
            config.learningRate,
            config.batchNorm,
            config.weightDecay
        )
        lossCriteria = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=config.learningRate, weight_decay=config.weightDecay)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        for i in range(config.epochs):
            model.train()
            tempLoss = 0.0
            true = 0
            total = 0
            for inputs, labels in testLoader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = lossCriteria(outputs, labels)
                loss.backward()
                optimizer.step()
                tempLoss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                true += predicted.eq(labels).sum().item()

            testLoss = tempLoss/len(testLoader)
            testAccuracy = 100*(true/total)

            wandb.log({"test loss": testLoss, "test accuracy": testAccuracy, "epoch": i+1})

            print(f"epoch {i+1}/{config.epochs}: test loss: {testLoss}, test accuracy: {testAccuracy}")

#Sweep Configuration
# Parse arguments
parser = argparse.ArgumentParser(description='CNN Training Configuration')
parser.add_argument('--weightDecay', type=float, default=0)
parser.add_argument('--dropout', type=float, default=0.1)
parser.add_argument('--learningRate', type=float, default=0.0001)
parser.add_argument('--activation', type=str, default='ELU')
parser.add_argument('--batchNorm', type=bool, default=True)
parser.add_argument('--filters', nargs='+', type=int, default=[32, 64, 128, 256, 512])
parser.add_argument('--dataAug', type=bool, default=True)
parser.add_argument('--batchSize', type=int, default=32)
parser.add_argument('--denseLayer', type=int, default=256)
parser.add_argument('--epochs', type=int, default=10)

args = parser.parse_args()

# Train the network with the parsed arguments
trainNetwork(args)