{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, SubsetRandomSampler\n","!pip install wandb\n","import wandb\n","wandb.init(entity=\"vishnukundhan333\", project=\"DL Assignment-2\")\n","# Q1\n","# Define a CNN model class with 5 convolutional layers, activation, and max-pooling functions between layers\n","class CNN(nn.Module):\n","    def __init__(self, filters, denseLayer, activation, inputShape, outputShape, dropout, learningRate, batchNorm, weightDecay):\n","        super(CNN, self).__init__()\n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(inputShape[0], filters[0], kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=3, padding=1)\n","        # Max-pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(4*4*filters[4], denseLayer)\n","        self.fc2 = nn.Linear(denseLayer, outputShape)\n","        # Activation function\n","        self.activation = getattr(nn, activation)()\n","        self.dropout = nn.Dropout(dropout)\n","        # Batch normalization\n","        self.batch_norm = nn.BatchNorm2d(filters[0]) if batchNorm else None\n","        self.weight_decay = weightDecay\n","        self.learning_rate = learningRate\n","        self.y = filters[4]\n","    # Forward function to propagate input data through the layers of the network\n","    def forward(self, x):\n","        x = self.pool(self.activation(self.conv1(x)))\n","        x = self.pool(self.activation(self.conv2(x)))\n","        x = self.pool(self.activation(self.conv3(x)))\n","        x = self.pool(self.activation(self.conv4(x)))\n","        x = self.pool(self.activation(self.conv5(x)))\n","        x = x.view(-1, self.y*4*4)  \n","        x = self.dropout(self.activation(self.fc1(x)))\n","        x = self.fc2(x)\n","        return x\n","\n","# Data preprocessing: resizing and converting to tensors\n","transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n","\n","# Splitting dataset into training and validation sets (80%, 20%)\n","trainDataset = datasets.ImageFolder(\"/kaggle/input/inaturalist12k/Data/inaturalist_12K/train/\", transform=transform)\n","trainIndices, valIndices = train_test_split(list(range(len(trainDataset))), test_size=0.2, random_state=42)\n","trainSampler, valSampler = SubsetRandomSampler(trainIndices), SubsetRandomSampler(valIndices)\n","\n","# Function to train the CNN model\n","def trainNetwork():\n","    with wandb.init() as run:\n","        config = wandb.config\n","        trainLoader = DataLoader(trainDataset, batch_size=config.batchSize, sampler=trainSampler)\n","        valLoader = DataLoader(trainDataset, batch_size=config.batchSize, sampler=valSampler)\n","        # Initialize CNN model\n","        model = CNN(\n","            config.filters,\n","            config.denseLayer,\n","            config.activation,\n","            (3, 128, 128),\n","            10,\n","            config.dropout,\n","            config.learningRate,\n","            config.batchNorm,\n","            config.weightDecay\n","        )\n","        # Define loss criterion and optimizer\n","        lossCriteria = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=config.learningRate, weight_decay=config.weightDecay)\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model.to(device)\n","        # Training loop\n","        for i in range(config.epochs):\n","            model.train()\n","            tempLoss = 0.0\n","            true = 0\n","            total = 0\n","            for inputs, labels in trainLoader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = lossCriteria(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                tempLoss += loss.item()\n","                _, predicted = outputs.max(1)\n","                total += labels.size(0)\n","                true += predicted.eq(labels).sum().item()\n","\n","            #Calculating validation loss and validation accuracy\n","            trainLoss = tempLoss/len(trainLoader)\n","            trainAccuracy = 100*(true/total)\n","            valLoss, valAccuracy = validateNetwork(valLoader, model)\n","\n","            #wandb log\n","            wandb.log({\"train loss\": trainLoss, \"train accuracy\": trainAccuracy, \"val loss\": valLoss, \"val accuracy\": valAccuracy,\"epoch\": i+1})\n","\n","# Validation function\n","def validateNetwork(valLoader,model):\n","    model.eval()\n","    valLoss = 0.0\n","    true = 0\n","    total = 0\n","    lossCriteria = nn.CrossEntropyLoss()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    with torch.no_grad():\n","        for inputs, labels in valLoader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            loss = lossCriteria(outputs, labels)\n","            valLoss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            true += predicted.eq(labels).sum().item()\n","\n","    valLoss /= len(valLoader)\n","    valAccuracy = 100*(true/total)\n","    return valLoss, valAccuracy\n","\n","# Sweep configuration\n","sweepConfig = {\n","    'method': 'bayes',\n","    'metric': {'name': 'Validation Accuracy','goal': 'maximize'},\n","    'parameters': {\n","        'weightDecay': {'values': [0, 0.0001, 0.0005]},\n","        'dropout': {'values': [0, 0.1, 0.2]},\n","        'learningRate': {'values': [0.0001, 0.00001]},\n","        'activation': {'values': ['ReLU', 'ELU', 'SELU']},\n","        'batchNorm': {'values': [True, False]},\n","        'filters': {\n","            'values': [[32, 32, 32, 32, 32], \n","                       [128, 64, 64, 32, 32], \n","                       [32, 64, 128, 256, 512]]\n","        },\n","        'dataAug': {'values': [True, False]},\n","        'batchSize': {'values': [32, 64]},\n","        'denseLayer': {'values': [64, 128, 256, 512]},\n","        'epochs': {'values': [5,10]}\n","    }\n","}\n","\n","# Initialize sweep\n","sweep_id = wandb.sweep(sweepConfig, project=\"DL Assignment-2\", entity=\"vishnukundhan333\")\n","\n","# Run the sweep\n","wandb.agent(sweep_id, trainNetwork, project=\"DL Assignment-2\", entity=\"vishnukundhan333\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, SubsetRandomSampler\n","!pip install wandb\n","import wandb\n","wandb.init(entity=\"vishnukundhan333\", project=\"DL Assignment-2\")\n","\n","# Define a CNN model class with 5 convolutional layers, activation, and max-pooling functions between layers\n","class CNN(nn.Module):\n","    def __init__(self, filters, denseLayer, activation, inputShape, outputShape, dropout, learningRate, batchNorm, weightDecay):\n","        super(CNN, self).__init__()\n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(inputShape[0], filters[0], kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(filters[0], filters[1], kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(filters[1], filters[2], kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(filters[2], filters[3], kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(filters[3], filters[4], kernel_size=3, padding=1)\n","        # Max-pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(4*4*filters[4], denseLayer)\n","        self.fc2 = nn.Linear(denseLayer, outputShape)\n","        # Activation function\n","        self.activation = getattr(nn, activation)()\n","        # Dropout layer\n","        self.dropout = nn.Dropout(dropout)\n","        # Batch normalization\n","        self.batch_norm = nn.BatchNorm2d(filters[0]) if batchNorm else None\n","        self.weight_decay = weightDecay\n","        self.learning_rate = learningRate\n","        self.y = filters[4]\n","\n","    # Forward function to propagate input data through the layers of the network\n","    def forward(self, x):\n","        x = self.pool(self.activation(self.conv1(x)))\n","        x = self.pool(self.activation(self.conv2(x)))\n","        x = self.pool(self.activation(self.conv3(x)))\n","        x = self.pool(self.activation(self.conv4(x)))\n","        x = self.pool(self.activation(self.conv5(x)))\n","        x = x.view(-1, self.y*4*4)  \n","        x = self.dropout(self.activation(self.fc1(x)))\n","        x = self.fc2(x)\n","        return x\n","\n","# Data preprocessing: resizing and converting to tensors\n","transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n","\n","# Getting test data set\n","testDataset = datasets.ImageFolder(\"/kaggle/input/inaturalist12k/Data/inaturalist_12K/val/\", transform=transform)\n","testLoader = DataLoader(testDataset, batch_size=32)\n","\n","# Function to train the CNN model\n","def trainNetwork():\n","    with wandb.init() as run:\n","        config = wandb.config\n","        # Initialize CNN model\n","        model = CNN(\n","            config.filters,\n","            config.denseLayer,\n","            config.activation,\n","            (3, 128, 128),\n","            10,\n","            config.dropout,\n","            config.learningRate,\n","            config.batchNorm,\n","            config.weightDecay\n","        )\n","        # Define loss criterion and optimizer\n","        lossCriteria = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=config.learningRate, weight_decay=config.weightDecay)\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model.to(device)\n","        # Testing loop\n","        for i in range(config.epochs):\n","            model.train()\n","            tempLoss = 0.0\n","            true = 0\n","            total = 0\n","            for inputs, labels in testLoader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = lossCriteria(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","                tempLoss += loss.item()\n","                _, predicted = outputs.max(1)\n","                total += labels.size(0)\n","                true += predicted.eq(labels).sum().item()\n","\n","            testLoss = tempLoss/len(testLoader)\n","            testAccuracy = 100*(true/total)\n","\n","            wandb.log({\"test loss\": testLoss, \"test accuracy\": testAccuracy, \"epoch\": i+1})\n","\n","# Sweep configuration\n","sweepConfig = {\n","    'method': 'bayes',\n","    'metric': {'name': 'Validation Accuracy','goal': 'maximize'},\n","    'parameters': {\n","        'weightDecay': {'values': [0]},\n","        'dropout': {'values': [0.1]},\n","        'learningRate': {'values': [0.0001]},\n","        'activation': {'values': ['ELU']},\n","        'batchNorm': {'values': [True]},\n","        'filters': {'values': [[32, 64, 128, 256, 512]]},\n","        'dataAug': {'values': [True]},\n","        'batchSize': {'values': [32]},\n","        'denseLayer': {'values': [256]},\n","        'epochs': {'values': [10]}\n","    }\n","}\n","\n","# Initialize sweep\n","sweep_id = wandb.sweep(sweepConfig, project=\"DL Assignment-2\", entity=\"vishnukundhan333\")\n","\n","# Run the sweep\n","wandb.agent(sweep_id, trainNetwork, project=\"DL Assignment-2\", entity=\"vishnukundhan333\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
